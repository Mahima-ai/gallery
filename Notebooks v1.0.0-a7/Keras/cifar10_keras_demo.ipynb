{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8214838",
   "metadata": {},
   "source": [
    "# BentoML Keras Tutorial\n",
    "\n",
    "This is a sample project demonstrating basic usage of BentoML with Keras.\n",
    "\n",
    "In this project, we will train a classifier model using Keras and the Cifar10 dataset, build an prediction service for serving the trained model via an HTTP server, and containerize the model server as a docker image for production deployment.\n",
    "\n",
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b401b96",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)\n",
    "\n",
    "## Normalizing the data\n",
    "def preprocessing_fun(data):\n",
    "    return data/255\n",
    "\n",
    "x_train_features = preprocessing_fun(x_train)\n",
    "x_test_features = preprocessing_fun(x_test)\n",
    "\n",
    "# Defining the neural network\n",
    "model = keras.Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Input(shape=x_train[0].shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    " \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "# Hidden layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "# last hidden layer i.e.. output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "## Training and fitting the model\n",
    "model.fit(\n",
    "      x_train_features, \n",
    "      y_train.flatten(), \n",
    "      validation_data=(x_test_features, y_test.flatten()), \n",
    "      batch_size=32,\n",
    "      epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b0b3f",
   "metadata": {},
   "source": [
    "## Save the model instance `model` to BentoML local model store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata ={'Accuracy':accuracy,'Precision':precision,'Recall':recall}\n",
    "\n",
    "labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "custom_obj={'labels': labels,\n",
    "      'preprocessing':preprocessing_fun}\n",
    "\n",
    "import bentoml\n",
    "tag = bentoml.pytorch.save('cifar10_classifier',\n",
    "                           model,\n",
    "                           metadata=metadata,\n",
    "                           custom_objects = custom_objects)\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc261e",
   "metadata": {},
   "source": [
    "## Create a BentoML Service for serving the model\n",
    "\n",
    "Note: using `%%writefile` here because bentoml.Service instance must be created in a separate .py file\n",
    "\n",
    "Here we define as many api endpoints as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb96530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T14:25:49.768886Z",
     "start_time": "2022-06-02T14:25:49.755657Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "# service.py\n",
    "import numpy as np\n",
    "import bentoml\n",
    "from bentoml.io import NumpyNdarray, Text, Image\n",
    "import PIL.Image\n",
    "\n",
    "model_tag = \"cifar10_classifier:latest\"\n",
    "# Load the runner for the latest Keras model we just saved\n",
    "cifar10_runner = bentoml.keras.load_runner(model_tag)\n",
    "cifar10_model = bentoml.models.get(model_tag)\n",
    "\n",
    "# Create the cifar10 service with the Keras runner\n",
    "# Multiple runners may be specified if needed in the runners array\n",
    "# When packaged as a bento, the runners here will included\n",
    "cnn = bentoml.Service(\"cifar10_classifier\", runners=[cifar10_runner])\n",
    "\n",
    "# Create API function with pre- and post- processing logic with your new \"cnn\" annotation\n",
    "@cnn.api(input=NumpyNdarray(), output=Text())\n",
    "def predict_array(input_series: np.ndarray) -> str:   \n",
    "    try:\n",
    "        # Define pre-processing logic\n",
    "        input_data = cifar10_model.custom_objects['preprocessing'](\n",
    "            input_series)\n",
    "        \n",
    "        result = cifar10_runner.run(input_data)\n",
    "        \n",
    "        # Define post-processing logic\n",
    "        result = cifar10_model.custom_objects['labels'][np.argmax(result)]\n",
    "        return result\n",
    "    except:\n",
    "        return 'Exception: Inappropriate input'\n",
    "\n",
    "\n",
    "@cnn.api(input=Image(), output=Text())\n",
    "def predict_image(f: PIL.Image) -> \"np.ndarray\":\n",
    "    try:\n",
    "        arr = np.array(f)\n",
    "        input_data = cifar10_model.custom_objects['preprocessing'](arr)\n",
    "        result = cifar10_runner.run(input_data)\n",
    "        # Define post-processing logic\n",
    "        result = cifar10_model.custom_objects['labels'][np.argmax(result)]\n",
    "        return result\n",
    "    except:\n",
    "        return 'Exception: Invalid input'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb358fd5",
   "metadata": {},
   "source": [
    "Start a dev model server to test out the service defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve service.py:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3750d39",
   "metadata": {},
   "source": [
    "Open your web browser at http://127.0.0.1:3000 to view the Bento UI for sending test requests. Now you can use something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d42c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Array data\n",
    "\n",
    "import requests,json \n",
    "def test_numpy(host, img_data):\n",
    "    img_json=json.dumps(img_data.tolist())\n",
    "    print('Sending Request')\n",
    "    resp = requests.post(\n",
    "        url = f\"http://{host}/predict_array\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        data=img_json,\n",
    "           )\n",
    "    print('Response')\n",
    "    return resp\n",
    "\n",
    "\n",
    "## Image Data\n",
    "from PIL import Image \n",
    "\n",
    "def test_image(host, img_path):\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "    print('Sending Request')\n",
    "    resp = requests.post(\n",
    "        url = f\"http://{host}/predict_image\",\n",
    "        headers={\"Content-Type\": \"image/png\"},\n",
    "        data=img_bytes,\n",
    "           )\n",
    "    print('Response')\n",
    "    return resp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d891b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=test_numpy('127.0.0.1:3000', x_test[2100])\n",
    "print(response.text)\n",
    "\n",
    "img_path = f\"sample_image.png\"\n",
    "response=test_image('127.0.0.1:3000',img_path)\n",
    "response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ffd79",
   "metadata": {},
   "source": [
    "## Build a Bento for distribution and deployment\n",
    "\n",
    "Bento is the distribution format in BentoML which captures all the source code, model files, config files and dependency specifications required for running the service for production deployment. Think of it as Docker/Container designed for machine learning models.\n",
    "\n",
    "Create a bento file `bentofile.yaml` for building a Bento for the service:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221d531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T14:25:56.405762Z",
     "start_time": "2022-06-02T14:25:56.401434Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile bentofile.yaml\n",
    "\n",
    "service: \"service.py:cnn\"  # A convention for locating your service: <YOUR_SERVICE_PY>:<YOUR_SERVICE_ANNOTATION>\n",
    "description: \"file: ./README.md\"\n",
    "labels:\n",
    "    owner: bentoml-team\n",
    "    stage: demo\n",
    "include:\n",
    " - \"*.py\"  # A pattern for matching which files to include in the bento\n",
    "python:\n",
    "  packages:\n",
    "   - keras # Additional libraries to be included in the bento\n",
    "   - numpy\n",
    "   - Pillow\n",
    "   - tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580dfdaf",
   "metadata": {},
   "source": [
    "Simply run `bentoml build` from current directory to build a Bento with the latest version of the tensorflow_mnist model. This may take a while when running for the first time for BentoML to resolve all dependency versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ac85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca64a5a",
   "metadata": {},
   "source": [
    "Starting a dev server with the Bento build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve cifar10_classifier:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edb7a8",
   "metadata": {},
   "source": [
    "## Containerize and Deployment\n",
    "\n",
    "Bento is designed to be deployed to run efficiently in a variety of different environments. And there are lots of deployment options and tools as part of the BentoML eco-system, such as Yatai and bentoctl for direct deployment to cloud platforms.\n",
    "\n",
    "In this guide, we will show you the most basic way of deploying a Bento, which is converting a Bento into a Docker image containing the HTTP model server.\n",
    "\n",
    "Make sure you have docker installed and docker deamon running, and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml containerize cifar10_classifier:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366f509",
   "metadata": {},
   "source": [
    "This will build a new docker image with all source code, model files and dependencies in place, and ready for production deployment. To start a container with this docker image locally, run:\n",
    "\n",
    "`docker run -p 3000:3000 cifar10_classifier:c5nnhiw7666ijgh2 `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b9552",
   "metadata": {},
   "source": [
    "## What's Next?,\n",
    "   \n",
    "  - 👉 [Pop into our Slack community!](https://l.linklyhq.com/l/ktO8) We're happy to help with any issue you face or even just to meet you and hear what you're working on.,\n",
    "   \n",
    "  - Dive deeper into the [Core Concepts](https://docs.bentoml.org/en/v1.0.0-a7/concepts/index.html) in BentoML,\n",
    "  \n",
    "  - Learn how to use BentoML with other ML Frameworks at [Frameworks Guide](https://docs.bentoml.org/en/v1.0.0-a7/frameworks/index.html) or check out other [gallery projects](https://github.com/bentoml/gallery),\n",
    "  - Learn more about model deployment options for Bento:,\n",
    "      - [🦄️ Yatai](https://github.com/bentoml/Yatai): Model Deployment at scale on Kubernetes,\n",
    "      - [🚀 bentoctl](https://github.com/bentoml/bentoctl): Fast model deployment on any cloud platform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
