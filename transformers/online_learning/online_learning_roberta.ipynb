{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bf0361",
   "metadata": {},
   "source": [
    "# Online learning with Transformers ü§ù BentoML\n",
    "\n",
    "In this Jupyter notebook file, we will perform Online learning with a fine-tune version trained from [our fine-tune guide](./fine_tune_roberta.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd478c60",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78490eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aac163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "import bentoml\n",
    "\n",
    "import transformers\n",
    "\n",
    "TASKS = \"text-classification\"\n",
    "FT_NAME = \"drobert_ft\"\n",
    "PRETRAINED = \"emotion_distilroberta_base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71da52b",
   "metadata": {},
   "source": [
    "## Import fine-tune model from BentoML modelstore\n",
    "\n",
    "There are two ways to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea47ab",
   "metadata": {},
   "source": [
    "### 1. Import from HuggingFace Hub\n",
    "\n",
    "If users already run our fine-tune notebook, then skips to [here](#Afterwards), otherwise run the two below cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d4c20",
   "metadata": {},
   "source": [
    "Users can also imports the fine-tune version in [this notebook](./fine_tune_roberta.ipynb) from [HuggingFace Hub](https://huggingface.co/aarnphm/finetune_emotion_distilroberta), and then save it to BentoML modelstore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_MODEL = \"aarnphm/finetune_emotion_distilroberta\"\n",
    "m1 = transformers.AutoModelForSequenceClassification.from_pretrained(FINETUNE_MODEL)\n",
    "t1 = transformers.AutoTokenizer.from_pretrained(FINETUNE_MODEL)\n",
    "_ = bentoml.transformers.save(FT_NAME, m1, tokenizer=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "m2 = transformers.AutoModelForSequenceClassification.from_pretrained(PRETRAINED_MODEL)\n",
    "t2 = transformers.AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "_ = bentoml.transformers.save(PRETRAINED, m2, tokenizer=t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d3890",
   "metadata": {},
   "source": [
    "### 2. Running [`fine_tune_roberta.ipynb`](./fine_tune_roberta.ipynb)\n",
    "Refers to [`fine_tune_roberta.ipynb`](./fine_tune_roberta.ipynb) to see how to fine-tune this model with Transformers.\n",
    "\n",
    "### Afterwards\n",
    "Load the model for testing with `bentoml.transformers.load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49e10de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:30:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> JAX version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, Flax version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:30:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m JAX version \u001b[1;36m0.2\u001b[0m.\u001b[1;36m28\u001b[0m, Flax version \u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m available.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config, model, tokenizer = bentoml.transformers.load(f\"{FT_NAME}:latest\", return_config=True)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86924b",
   "metadata": {},
   "source": [
    "### Offline serving\n",
    "One can load the aboved `model`, `tokenizer`, and `config` to a `text-classification` pipeline to test with offline serving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e23ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarnphm/mambaforge/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'sadness', 'score': 0.059696026146411896},\n",
       "  {'label': 'joy', 'score': 0.08176055550575256},\n",
       "  {'label': 'love', 'score': 0.8277080059051514},\n",
       "  {'label': 'anger', 'score': 0.017906058579683304},\n",
       "  {'label': 'fear', 'score': 0.007731563411653042},\n",
       "  {'label': 'surprise', 'score': 0.00519789382815361}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline = transformers.pipeline(TASKS, model=model, tokenizer=tokenizer, config=config, return_all_scores=True)  # type: ignore\n",
    "clf_pipeline(\"I love you so much.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc27a4",
   "metadata": {},
   "source": [
    "One can also Verify this model in a runner for offline serving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bb857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:33:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> JAX version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, Flax version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:33:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m JAX version \u001b[1;36m0.2\u001b[0m.\u001b[1;36m28\u001b[0m, Flax version \u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m available.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'love', 'score': 0.26683616638183594},\n",
       " {'label': 'love', 'score': 0.8373624086380005},\n",
       " {'label': 'anger', 'score': 0.48438775539398193}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = bentoml.transformers.load_runner(\n",
    "    f\"{FT_NAME}:latest\", tasks=TASKS, return_all_scores=False\n",
    ")\n",
    "\n",
    "runner.run_batch([\"Hello World\", \"I love you\", \"I hate you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0661140",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> using `run_batch` should only be used for offline serving.\n",
    "\n",
    "In the context of a BentoML Service, `run_batch` or `async_run_batch` shouldn't\n",
    "be used as the BentoML's dynamic batching is <b>NOT ENABLED</b>.\n",
    "\n",
    "If users want to utilize multiple inputs for a request, BentoML support _composing inference graph_, which will be demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58877ea6",
   "metadata": {},
   "source": [
    "## Create a BentoML service\n",
    "<b>NOTE:</b> using `%%writefile` here because `bentoml.Service` instance must be created in a separate .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b27f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import re\n",
    "import typing as t\n",
    "import asyncio\n",
    "import unicodedata\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import JSON\n",
    "from bentoml.io import Text\n",
    "\n",
    "FT_MODEL_TAG = \"drobert_ft\"\n",
    "PRETRAINED_MODEL_TAG = \"emotion_distilroberta_base\"\n",
    "TASKS = \"text-classification\"\n",
    "\n",
    "ft_runner = bentoml.transformers.load_runner(FT_MODEL_TAG, tasks=TASKS, return_all_scores=True)\n",
    "\n",
    "pretrained_runner= bentoml.transformers.load_runner(PRETRAINED_MODEL_TAG, tasks=TASKS, return_all_scores=True)\n",
    "\n",
    "svc = bentoml.Service(name=\"online_learning_ft\", runners=[ft_runner, pretrained_runner])\n",
    "\n",
    "class Prediction(BaseModel):\n",
    "    input: str\n",
    "    sadness: float\n",
    "    joy: float\n",
    "    love: float\n",
    "    anger: float\n",
    "    fear: float\n",
    "    surprise: float\n",
    "\n",
    "class Outputs(BaseModel):\n",
    "    drobert_ft: Prediction\n",
    "    emotion_distilroberta_base: Prediction\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", s.lower().strip())\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def convert_result(res) -> t.Dict[str, t.Any]:\n",
    "    if isinstance(res, list):\n",
    "        return {l[\"label\"]: l[\"score\"] for l in res}\n",
    "    return {res[\"label\"]: res[\"score\"]}\n",
    "\n",
    "\n",
    "@svc.api(input=Text(), output=JSON(pydantic_model=Outputs))\n",
    "async def compare(sentences: str) -> t.Dict[str, t.Dict[str, t.Union[str, float]]]:\n",
    "    processed = normalize(sentences)\n",
    "    outputs = await asyncio.gather(\n",
    "        ft_runner.async_run(processed),\n",
    "        pretrained_runner.async_run(processed)\n",
    "    )\n",
    "    return {\n",
    "        name: {**convert_result(pred)}\n",
    "        for name, pred in zip(svc.runners.keys(), outputs)\n",
    "    }\n",
    "\n",
    "@svc.api(input=Text(), output=Text())\n",
    "async def online_learning(sentence: str) -> str:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd77fc3",
   "metadata": {},
   "source": [
    "\n",
    "We defined two separate endpoints `/compare` and `/online_learning`:\n",
    "1. `/compare` shows the results of our fine-tune models vs. the pretrained model.\n",
    "2. `/online_learning` takes in `sentence` as inputs and perform [Online learning](https://en.wikipedia.org/wiki/Online_machine_learning)\n",
    "\n",
    "NOTE: currently `/online_learning` is WIP. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586f5bd",
   "metadata": {},
   "source": [
    "\n",
    "Start a service with reload enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb147f76",
   "metadata": {},
   "source": [
    "With the `--reload` flag, the API server will automatically restart when the source file `service.py` is being updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c257b",
   "metadata": {},
   "source": [
    "One can then navigate to `127.0.0.1:3000` and interact with Swagger UI.\n",
    "One can also verify the endpoints locally with `curl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf540e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://localhost:3000/compare\" \\\n",
    "     -H \"accept: application/json\" \\\n",
    "     -H \"Content-Type: text/plain\" \\\n",
    "     -d \"\\\" I love you\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777a529",
   "metadata": {},
   "source": [
    "We can also do a simple local benchmark with [locust](https://locust.io/):\n",
    "```bash\n",
    "locust --headless -u 100 -r 1000 --run-time 2m --host http://127.0.0.1:3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860fd29",
   "metadata": {},
   "source": [
    "## Build a Bento for deployment\n",
    "\n",
    "A `bentofile.yaml` can be created to create a Bento with `bentoml build` in the current directory:\n",
    "```yaml\n",
    "service: \"service:svc\"\n",
    "description: \"file: ./README.md\"\n",
    "labels:\n",
    "  owner: bentoml-team\n",
    "  stage: demo\n",
    "include:\n",
    "- \"*.py\"\n",
    "exclude:\n",
    "- \"locustfile.py\"\n",
    "- \"tests/\"\n",
    "- \"*.ipynb\"\n",
    "python:\n",
    "  lock_packages: false\n",
    "  packages:\n",
    "    - -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "    - torch==1.10.2+cpu\n",
    "    - git+https://github.com/huggingface/transformers\n",
    "    - datasets\n",
    "    - pydantic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa86e7",
   "metadata": {},
   "source": [
    "Build a bento with `bentoml build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8d161",
   "metadata": {},
   "source": [
    "This Bento now can be served with `--production`:\n",
    "```bash\n",
    "bentoml serve online_learning_ft:latest --production\n",
    "```\n",
    "\n",
    "## Containerize a Bento\n",
    "\n",
    "Make sure Docker and daemon is running, then `bentoml containerize` will build\n",
    "a docker image for the model server aboved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml containerize online_learning_ft:latest\n",
    "# an example docker tag: online_learning_ft:zt4vvsurw63thgxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495435b",
   "metadata": {},
   "source": [
    "Test out the newly built docker image:\n",
    "```bash\n",
    "docker run -p 3000:3000 online_learning_ft:zt4vvsurw63thgxi\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
