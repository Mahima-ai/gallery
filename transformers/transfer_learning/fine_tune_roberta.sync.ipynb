{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7fc87b",
   "metadata": {},
   "source": [
    "# Transfer learning with Transformers ü§ù BentoML\n",
    "\n",
    "[Source](https://github.com/bentoml/gallery/tree/main/transformers/roberta_text_classification/transfer_learning/fine_tune_roberta.sync.ipynb) | [nbviewer](https://nbviewer.org/github/bentoml/gallery/blob/main/transformers/roberta_text_classification/transfer_learning/fine_tune_roberta.sync.ipynb) | [Colab](https://colab.research.google.com/github/bentoml/gallery/blob/main/transformers/roberta_text_classification/transfer_learning/fine_tune_roberta.sync.ipynb)\n",
    "\n",
    "In this Jupyter notebook file, we will do transfer learning a version of [distilroberta-base](https://huggingface.co/distilroberta-base) for emotion detection (sentiment analysis) from text.\n",
    "\n",
    "<b>Stack: Transformers(<i>PyTorch backend</i>) - BentoML </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9829d",
   "metadata": {},
   "source": [
    "## Import pretrained model with BentoML\n",
    "Users can easily import the our fine tune model with `bentoml.models.import_model()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "tag = bentoml.models.import_model(\"./exported\")\n",
    "model, tokenizer = bentoml.transformers.load(tag, return_config=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac81e10",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> If you just want to use the provided model, stop here and go back to [README.md](../README.md) for next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535ab5e",
   "metadata": {},
   "source": [
    "## Fine-tuning for multi-class sentiment analysis in a different domain\n",
    "In this section, we will fine tune a version of [distilroberta-base](https://huggingface.co/distilroberta-base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8852a00",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d107740",
   "metadata": {},
   "source": [
    "### Setup pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ef4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python import_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93eea48",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7de7721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarnphm/mambaforge/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "from config import (\n",
    "    BENTOML_FINETUNE_NAME,\n",
    "    MODEL,\n",
    "    NUM_LABELS,\n",
    "    NUM_EPOCHS,\n",
    "    BATCH_SIZE,\n",
    "    LR,\n",
    "    WDECAY,\n",
    ")\n",
    "from transformers.trainer_utils import set_seed\n",
    "from datasets.load import load_dataset\n",
    "\n",
    "torch.set_num_threads(psutil.cpu_count())\n",
    "set_seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63605bd1",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "We will use [emotion](https://huggingface.co/datasets/emotion) via [huggingface/datasets](https://huggingface.co/docs/datasets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ad59f",
   "metadata": {},
   "source": [
    "We will load tokenizer from imported model from HuggingFace hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b75ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:39:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> JAX version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, Flax version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:39:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m JAX version \u001b[1;36m0.2\u001b[0m.\u001b[1;36m28\u001b[0m, Flax version \u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m available.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:39:57] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> BentoML won't support loading pipeline if users decide to save    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         pipeline with `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">save</span><span style=\"font-weight: bold\">()</span>`.                                                  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Since `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">load</span><span style=\"font-weight: bold\">()</span>` will always return model, and tokenizer. Users can easily \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         create a new pipeline:                                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             import bentoml                                                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             import transformers                                                  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             model, tokenizer = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">bentoml.transformers.load</span><span style=\"font-weight: bold\">(</span>tag<span style=\"font-weight: bold\">)</span>                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>             pipe = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">transformers.pipeline</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'text-classification'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">model</span>,     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>=<span style=\"color: #800080; text-decoration-color: #800080\">tokenizer</span><span style=\"font-weight: bold\">)</span>                                                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:39:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m BentoML won't support loading pipeline if users decide to save    \n",
       "\u001b[2;36m           \u001b[0m         pipeline with `\u001b[1;35msave\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m`.                                                  \n",
       "\u001b[2;36m           \u001b[0m         Since `\u001b[1;35mload\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m` will always return model, and tokenizer. Users can easily \n",
       "\u001b[2;36m           \u001b[0m         create a new pipeline:                                                   \n",
       "\u001b[2;36m           \u001b[0m             import bentoml                                                       \n",
       "\u001b[2;36m           \u001b[0m             import transformers                                                  \n",
       "\u001b[2;36m           \u001b[0m                                                                                  \n",
       "\u001b[2;36m           \u001b[0m             model, tokenizer = \u001b[1;35mbentoml.transformers.load\u001b[0m\u001b[1m(\u001b[0mtag\u001b[1m)\u001b[0m                    \n",
       "\u001b[2;36m           \u001b[0m             pipe = \u001b[1;35mtransformers.pipeline\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'text-classification'\u001b[0m, \u001b[33mmodel\u001b[0m=\u001b[35mmodel\u001b[0m,     \n",
       "\u001b[2;36m           \u001b[0m         \u001b[33mtokenizer\u001b[0m=\u001b[35mtokenizer\u001b[0m\u001b[1m)\u001b[0m                                                     \n",
       "\u001b[2;36m           \u001b[0m                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"tags.log\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tag = f.readline().strip(\"\\n\")\n",
    "_, tokenizer = bentoml.transformers.load(tag, return_config=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c5967",
   "metadata": {},
   "source": [
    "The following `preprocess_function` will [map](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map)\n",
    "all given text in the dataset to a tokenized version. We can then later use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "\n",
    "tokenized_emotion = emotion.map(preprocess_function, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4c178",
   "metadata": {},
   "source": [
    "We will use f1 and recall as our metrics for the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722a2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_tune/\", num_labels=NUM_LABELS, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_emotion.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_emotion[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97377b9",
   "metadata": {},
   "source": [
    "Setup training arguments as well as `transformers.Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = len(tokenized_emotion[\"train\"]) // BATCH_SIZE\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    weight_decay=WDECAY,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_emotion[\"train\"],\n",
    "    eval_dataset=tokenized_emotion[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1543db4",
   "metadata": {},
   "source": [
    "Transformers provided an easy way to fine-tune given models with `Trainer` API. Simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_output = trainer.train()\n",
    "trainer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f20c61",
   "metadata": {},
   "source": [
    "### Evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd933b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a090680",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(tokenized_emotion[\"validation\"])\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d846c",
   "metadata": {},
   "source": [
    "### Save our fine-tune model to BentoML modelstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8551af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:40:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> JAX version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, Flax version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:40:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m JAX version \u001b[1;36m0.2\u001b[0m.\u001b[1;36m28\u001b[0m, Flax version \u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m available.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> Successfully saved <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">tag</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"roberta_fine_tune:iaaofxeowcnlfgxi\"</span>,\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #808000; text-decoration-color: #808000\">path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/aarnphm/bentoml/models/roberta_fine_tune/iaaofxeowcnlfgxi/\"</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m Successfully saved \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtag\u001b[0m=\u001b[32m\"roberta_fine_tune\u001b[0m\u001b[32m:iaaofxeowcnlfgxi\"\u001b[0m,\n",
       "\u001b[2;36m           \u001b[0m         \u001b[33mpath\u001b[0m=\u001b[32m\"/Users/aarnphm/bentoml/models/roberta_fine_tune/iaaofxeowcnlfgxi/\"\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = results.update({\"transfer-learning\": True})\n",
    "tag = bentoml.transformers.save(BENTOML_FINETUNE_NAME, model, tokenizer=tokenizer, metadata=metadata)\n",
    "bentoml.models.export_model(tag, \"./exported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
