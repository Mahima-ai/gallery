{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56a76d9",
   "metadata": {},
   "source": [
    "# Pretrained serving with Transformers ü§ù BentoML\n",
    "\n",
    "In this Jupyter notebook file, we will use a pretrained version of [distilroberta-base](https://huggingface.co/distilroberta-base) for emotion detection from text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2eb746",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735630",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff82c1e",
   "metadata": {},
   "source": [
    "## Import pretrained model from HuggingFace to BentoML modelstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a756b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarnphm/mambaforge/lib/python3.9/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:50:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> JAX version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>, Flax version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:50:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m JAX version \u001b[1;36m0.2\u001b[0m.\u001b[1;36m28\u001b[0m, Flax version \u001b[1;36m0.4\u001b[0m.\u001b[1;36m0\u001b[0m available.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:51:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>boot<span style=\"font-weight: bold\">]</span> Successfully saved                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">tag</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"roberta_text_classification:45xziluuggmtbgxi\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"/Users/aa</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">rnphm/bentoml/models/roberta_text_classification/45xziluuggmtbgxi/\"</span><span style=\"font-weight: bold\">)</span>     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:51:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mboot\u001b[1m]\u001b[0m Successfully saved                                                \n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtag\u001b[0m=\u001b[32m\"roberta_text_classification\u001b[0m\u001b[32m:45xziluuggmtbgxi\"\u001b[0m, \u001b[33mpath\u001b[0m=\u001b[32m\"/Users/aa\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32mrnphm/bentoml/models/roberta_text_classification/45xziluuggmtbgxi/\"\u001b[0m\u001b[1m)\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bentoml\n",
    "import transformers\n",
    "\n",
    "TASKS = \"text-classification\"\n",
    "BENTOML_MODEL_NAME = \"roberta_text_classification\"\n",
    "MODEL = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "\n",
    "classifier = transformers.pipeline(TASKS, model=MODEL, return_all_scores=True)  # type: ignore\n",
    "tag = bentoml.transformers.save(BENTOML_MODEL_NAME, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e201d1",
   "metadata": {},
   "source": [
    "This will create a BentoML Model format with tag `roberta_text_classification`.\n",
    "One can retrieve this model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f22b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd93dc",
   "metadata": {},
   "source": [
    "Verify this model in a runner for offline serving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = bentoml.transformers.load_runner(\n",
    "    \"roberta_text_classification\", tasks=\"text-classification\", return_all_scores=True\n",
    ")\n",
    "\n",
    "runner.run_batch([\"Hello World\", \"I love you\", \"I hate you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7089fe7",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> using `run_batch` should only be used for offline serving. \n",
    "\n",
    "In the context of a BentoML Service, `run_batch` or `async_run_batch` shouldn't \n",
    "be used as the BentoML's dynamic batching is <b>NOT ENABLED</b>.\n",
    "\n",
    "If users want to utilize multiple inputs for a request, BentoML support _composing inference graph_, which will be demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758ae65",
   "metadata": {},
   "source": [
    "## Create a BentoML service\n",
    "<b>NOTE:</b> using `%%writefile` here because `bentoml.Service` instance must be created in a separate .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4693f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import re\n",
    "import typing as t\n",
    "import asyncio\n",
    "import unicodedata\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import JSON\n",
    "from bentoml.io import Text\n",
    "\n",
    "\n",
    "MODEL_NAME = \"roberta_text_classification\"\n",
    "TASKS = \"text-classification\"\n",
    "\n",
    "clf_runner = bentoml.transformers.load_runner(MODEL_NAME, tasks=TASKS)\n",
    "\n",
    "all_runner = bentoml.transformers.load_runner(\n",
    "    MODEL_NAME, name=\"all_score_runner\", tasks=TASKS, return_all_scores=True\n",
    ")\n",
    "\n",
    "svc = bentoml.Service(name=\"pretrained_clf\", runners=[clf_runner, all_runner])\n",
    "\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", s.lower().strip())\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def preprocess(sentence: t.Dict[str, t.List[str]]) -> t.Dict[str, t.List[str]]:\n",
    "    assert 'text' in sentence, \"Given JSON does not contain `text` field\"\n",
    "    if not isinstance(sentence['text'], list):\n",
    "        sentence['text'] = [sentence['text']]\n",
    "    return {k: [normalize(s) for s in v] for k, v in sentence.items()}\n",
    "\n",
    "\n",
    "def convert_result(res) -> t.Dict[str, t.Any]:\n",
    "    if isinstance(res, list):\n",
    "        return {l[\"label\"]: l[\"score\"] for l in res}\n",
    "    return {res[\"label\"]: res[\"score\"]}\n",
    "\n",
    "\n",
    "def postprocess(\n",
    "    inputs: t.Dict[str, t.List[str]], outputs: t.List[t.Dict[str, t.Any]]\n",
    ") -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    return {\n",
    "        i: {\"input\": sent, **convert_result(pred)}\n",
    "        for i, (sent, pred) in enumerate(zip(inputs[\"text\"], outputs))\n",
    "    }\n",
    "\n",
    "\n",
    "@svc.api(input=Text(), output=JSON())\n",
    "async def sentiment(sentence: str) -> t.Dict[str, t.Any]:\n",
    "    res = await clf_runner.async_run(sentence)\n",
    "    return {\"input\": sentence, \"label\": res['label']}\n",
    "\n",
    "\n",
    "@svc.api(input=JSON(), output=JSON())\n",
    "async def batch_sentiment(sentences: t.Dict[str, t.List[str]]) -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    processed = preprocess(sentences)\n",
    "    outputs = await asyncio.gather(*[clf_runner.async_run(s) for s in processed[\"text\"]])\n",
    "    return postprocess(processed, outputs)  # type: ignore\n",
    "\n",
    "\n",
    "@svc.api(input=JSON(), output=JSON())\n",
    "async def batch_all_scores(sentences: t.Dict[str, t.List[str]]) -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    processed = preprocess(sentences)\n",
    "    outputs = await asyncio.gather(*[all_runner.async_run(s) for s in processed[\"text\"]])\n",
    "    return postprocess(processed, outputs)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e2f7f",
   "metadata": {},
   "source": [
    "\n",
    "We defined two separate endpoints `/batch_sentiment` and `batch_all_scores` which both creates an inference graph to make use of BentoML's dynamic batching.\n",
    "\n",
    "We also create `/sentiment` endpoints which accept a single sentence as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cc61f",
   "metadata": {},
   "source": [
    "\n",
    "Start a service with reload enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0883da2",
   "metadata": {},
   "source": [
    "With the `--reload` flag, the API server will automatically restart when the source file `service.py` is being updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bceace0",
   "metadata": {},
   "source": [
    "One can then navigate to `127.0.0.1:3000` and interact with Swagger UI.\n",
    "One can also verify the endpoints locally with `curl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed32044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://localhost:3000/batch_sentiment\" \\\n",
    "      -H \"accept: application/json\" \\\n",
    "      -H \"Content-Type: application/json\" \\\n",
    "      -d \"{\\\"text\\\":[\\\"I love you with all my hearts :)\\\",\\\"Our path diverges\\\"]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a6457",
   "metadata": {},
   "source": [
    "We can also do a simple local benchmark with [locust](https://locust.io/):\n",
    "```bash\n",
    "locust --headless -u 100 -r 1000 --run-time 2m --host http://127.0.0.1:3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42948f3",
   "metadata": {},
   "source": [
    "## Build a Bento for deployment\n",
    "\n",
    "A `bentofile.yaml` can be created to create a Bento with `bentoml build` in the current directory:\n",
    "```yaml\n",
    "service: \"service:svc\"\n",
    "description: \"file: ./README.md\"\n",
    "labels:\n",
    "  owner: bentoml-team\n",
    "  stage: demo\n",
    "include:\n",
    "- \"*.py\"\n",
    "exclude:\n",
    "- \"locustfile.py\"\n",
    "- \"tests/\"\n",
    "- \"*.ipynb\"\n",
    "python:\n",
    "  lock_packages: false\n",
    "  packages:\n",
    "    - -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "    - torch==1.10.2+cpu\n",
    "    - git+https://github.com/huggingface/transformers\n",
    "    - datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c718d",
   "metadata": {},
   "source": [
    "Build a bento with `bentoml build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60255359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bce58f",
   "metadata": {},
   "source": [
    "This Bento now can be served with `--production`:\n",
    "```bash\n",
    "bentoml serve pretrained_clf:latest --production\n",
    "```\n",
    "\n",
    "## Containerize a Bento\n",
    "\n",
    "Make sure Docker and daemon is running, then `bentoml containerize` will build\n",
    "a docker image for the model server aboved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml containerize pretrained_clf:latest\n",
    "# an example docker tag: pretrained_clf:zt4vvsurw63thgxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be7f67",
   "metadata": {},
   "source": [
    "Test out the newly built docker image:\n",
    "```bash\n",
    "docker run -p 3000:3000 pretrained_clf:zt4vvsurw63thgxi\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
